{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "# import timm\n",
    "import pandas as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.amp import GradScaler\n",
    "import cv2\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.autograd import Variable\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import pandas as pd\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in d:\\anaconda\\lib\\site-packages (1.0.12)\n",
      "Requirement already satisfied: torch in d:\\anaconda\\lib\\site-packages (from timm) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in d:\\anaconda\\lib\\site-packages (from timm) (0.20.1+cu121)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\lib\\site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in d:\\anaconda\\lib\\site-packages (from timm) (0.27.0)\n",
      "Requirement already satisfied: safetensors in d:\\anaconda\\lib\\site-packages (from timm) (0.4.5)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\anaconda\\lib\\site-packages (from huggingface_hub->timm) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\danie\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub->timm) (24.2)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\anaconda\\lib\\site-packages (from huggingface_hub->timm) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\danie\\appdata\\roaming\\python\\python312\\site-packages (from huggingface_hub->timm) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch->timm) (3.1.4)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from torch->timm) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\anaconda\\lib\\site-packages (from torch->timm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\anaconda\\lib\\site-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision->timm) (10.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\danie\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.42.1->huggingface_hub->timm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->huggingface_hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->huggingface_hub->timm) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_msk = np.load('/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/msk_array.npy')\n",
    "train_images = sorted(os.listdir('/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/data/train'))\n",
    "test_images = sorted(os.listdir('/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/data/test'))\n",
    "test_msk = np.zeros((len(test_images), train_msk.shape[1], train_msk.shape[2]))\n",
    "\n",
    "train_images = [f'/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/data/train/{path}' for path in train_images]\n",
    "test_images = [f'/kaggle/input/ioai-2025-preparation-class-lesson-8-homework/data/test/{path}' for path in test_images]\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path_image, msks):\n",
    "\n",
    "        self.path_image = path_image\n",
    "        self.msks = msks\n",
    "        # Resize input image\n",
    "        self.image_size = 512\n",
    "\n",
    "    def resize(self, img, interp):\n",
    "        return  cv2.resize(\n",
    "            img, (self.image_size, self.image_size), interpolation=interp)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_image)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "\n",
    "        img = cv2.imread(self.path_image[i])\n",
    "        msk = self.msks[i]\n",
    "        msk = msk[:, :, None]\n",
    "\n",
    "        # img = cv2.resize(\n",
    "        #     img, (self.image_size, self.image_size), interpolation= cv2.INTER_LINEAR)\n",
    "        # msk = cv2.resize(\n",
    "        #     msk, (self.image_size, self.image_size), interpolation= cv2.INTER_LINEAR)\n",
    "\n",
    "        img = (img / 255.) - 0.5\n",
    "        img = np.transpose(img,(2,0,1)).astype(np.float32)\n",
    "        img = torch.from_numpy(img)\n",
    "        msk = torch.from_numpy(msk)\n",
    "\n",
    "        return img, msk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.unet = smp.Unet('efficientnet-b2',\n",
    "                             encoder_weights='imagenet',\n",
    "                             classes=1,\n",
    "                             decoder_channels=[256, 128, 64, 32, 16],\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        y = self.unet(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "batch_size = 4\n",
    "valid_batch_size = 4\n",
    "epochs = 7\n",
    "lr = 3.22e-4\n",
    "clip_grad_norm = 15.28\n",
    "DEVICE = 'cuda'\n",
    "params_train = {'batch_size': batch_size, 'shuffle': True, 'drop_last': True, 'num_workers': 2}\n",
    "params_val = {'batch_size': batch_size, 'shuffle': False, 'drop_last': False, 'num_workers': 2}\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(Dataset(train_images[:-70], train_msk[:-70]), **params_train)\n",
    "val_loader = torch.utils.data.DataLoader(Dataset(train_images[-70:], train_msk[-70:]), **params_val)\n",
    "\n",
    "model = Model().cuda()\n",
    "num_train_steps = int(len(train_loader) / batch_size  * epochs)\n",
    "loss_func= smp.losses.DiceLoss(mode=\"binary\", smooth=1.)\n",
    "\n",
    "scaler = GradScaler('cuda')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader) * epochs, 1e-6)\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    average_loss = 0\n",
    "    tk0 = tqdm(enumerate(train_loader), total = len(train_loader))\n",
    "    for batch_number,  (img, target)  in tk0:\n",
    "        optimizer.zero_grad()\n",
    "        img = img.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        # continue\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(img)\n",
    "            loss = loss_func(outputs, target)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        average_loss += loss.cpu().detach().numpy()\n",
    "        tk0.set_postfix(loss=average_loss / (batch_number + 1),lr = scheduler.get_last_lr()[0], stage=\"train\", epoch = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "params_val = {'batch_size': batch_size, 'shuffle': False, 'drop_last': False, 'num_workers': 2}\n",
    "test_loader = torch.utils.data.DataLoader(Dataset(test_images, test_msk), **params_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "imgs_list = []\n",
    "target_list = []\n",
    "model.eval()\n",
    "average_loss = 0\n",
    "with torch.no_grad():\n",
    "    for batch_number,  (img, target)  in enumerate(test_loader):\n",
    "        img = img.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            outputs = model(img)\n",
    "\n",
    "        preds += [outputs.sigmoid().to('cpu').numpy()]\n",
    "\n",
    "preds = np.concatenate(preds)[:, 0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "preds = (preds > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def rle_encode(x, fg_val=1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x:  numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns: run length encoding as list\n",
    "    \"\"\"\n",
    "\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T sets Fortran order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def list_to_string(x):\n",
    "    \"\"\"\n",
    "    Converts list to a string representation\n",
    "    Empty list returns '-'\n",
    "    \"\"\"\n",
    "    if x: # non-empty list\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "true_list = [list_to_string(rle_encode(ans)) for ans in preds]\n",
    "\n",
    "predict_df = pd.DataFrame()\n",
    "predict_df['Id'] = [f'{x:03d}.jpg' for x in range(150)]\n",
    "predict_df['Target'] = true_list\n",
    "predict_df.to_csv('submission.csv', index = None)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
