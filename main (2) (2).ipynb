{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as tt\n",
    "from torchvision.io import read_image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import models as vision_models\n",
    "import timm\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.io import decode_image\n",
    "from pathlib import Path\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "source_dir = r\"journey-springfield\\train\"\n",
    "target_dir = os.path.join(os.path.dirname(source_dir), \"dataset\", \"images\")\n",
    "csv_path = os.path.join(os.path.dirname(source_dir), \"dataset\", \"labels.csv\")\n",
    "\n",
    "# Создаем целевую директорию, если её нет\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Массив для хранения данных\n",
    "data = []\n",
    "\n",
    "# Перебираем классы в исходной директории\n",
    "for class_name in os.listdir(source_dir):\n",
    "    class_path = os.path.join(source_dir, class_name)\n",
    "    \n",
    "    if not os.path.isdir(class_path): \n",
    "        continue\n",
    "\n",
    "    # Перебираем изображения в каждом классе\n",
    "    for img_name in os.listdir(class_path):\n",
    "        img_path = os.path.join(class_path, img_name)\n",
    "        new_img_path = os.path.join(target_dir, img_name)\n",
    "\n",
    "        # Проверяем, существует ли уже файл с таким именем\n",
    "        if os.path.exists(new_img_path):\n",
    "            base, ext = os.path.splitext(img_name)\n",
    "            new_img_name = f\"{base}_{class_name}{ext}\"\n",
    "            new_img_path = os.path.join(target_dir, new_img_name)\n",
    "\n",
    "        # Перемещаем изображение в целевую директорию\n",
    "        shutil.move(img_path, new_img_path)\n",
    "\n",
    "        # Добавляем путь к изображению и класс в список\n",
    "        rel_path = os.path.relpath(new_img_path, os.path.dirname(csv_path))\n",
    "        data.append([rel_path, class_name])\n",
    "\n",
    "# Создаем DataFrame и сохраняем его в CSV\n",
    "df = pd.DataFrame(data, columns=[\"image_path\", \"class\"])\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Готово! Все изображения перемещены в {target_dir}, CSV создан по пути {csv_path}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17793, 3) (3140, 3)\n"
     ]
    }
   ],
   "source": [
    "le1 = LabelEncoder()\n",
    "data = pd.read_csv(r'journey-springfield\\dataset\\labels.csv')\n",
    "data['class_id'] = le1.fit_transform(data['class'])\n",
    "data['class_id'] = data['class_id'].astype('int64')\n",
    "train, val = train_test_split(data, test_size=0.15, random_state=1, stratify=data['class'])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "val = val.reset_index(drop=True)\n",
    "\n",
    "print(train.shape, val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = r'journey-springfield\\dataset'\n",
    "data['unified_class'] = data['class']\n",
    "train['unified_class'] = train['class']\n",
    "train = train.drop('class',axis = 1)\n",
    "val['unified_class'] = val['class']\n",
    "val = val.drop('class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.model = vision_models.efficientnet_b1(vision_models.EfficientNet_B1_Weights.DEFAULT)\n",
    "        self.model.classifier[1] = torch.nn.Linear(self.model.classifier[1].in_features, num_classes)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        inputs, _ = batch\n",
    "        return self.model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpDataset(Dataset):\n",
    "    def __init__(self, dataframe: pd.DataFrame, path_to_images: Path, transforms: tt.Compose) -> None:\n",
    "        self.df = dataframe\n",
    "        self.path_to_images = path_to_images\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # print(row)\n",
    "        image = Image.open(self.path_to_images + '\\\\' + row[\"image_path\"]).convert('RGB')\n",
    "        # print(image)\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        return image, row[\"class_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "img = read_image(images_path +'\\\\'+ data.iloc[idx][\"image_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescale_size = 244\n",
    "# Imagenet mean and standard (are calculated from all of images)\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406])\n",
    "imagenet_std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = tt.Compose([\n",
    "    tt.Resize((int(rescale_size * 1.25), int(rescale_size * 1.25))),\n",
    "    tt.RandomCrop(rescale_size),\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "val_transform = tt.Compose([\n",
    "    tt.Resize((int(rescale_size * 1.05), int(rescale_size * 1.05))),\n",
    "    tt.CenterCrop(rescale_size),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(imagenet_mean, imagenet_std)\n",
    "])\n",
    "\n",
    "train_dataset = SimpDataset(train, images_path, transforms=train_transform)\n",
    "val_dataset = SimpDataset(val, images_path, transforms=val_transform)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, num_workers=0, shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=64, num_workers=0, shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64,  shuffle=True)\n",
    "valid_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 18, 26, 15, 32, 39, 22, 27,  6,  4,  4, 36, 17, 22, 16, 37, 25,  4,\n",
       "        25, 29, 32, 15, 20, 20, 15, 20, 27,  4,  6, 24,  4, 22, 25,  6, 20, 28,\n",
       "        22, 17,  0,  3, 16, 32,  4, 17, 24, 37, 22, 32, 18, 22, 17, 28, 32, 15,\n",
       "        15, 28,  4, 15, 27, 37,  0, 15,  4, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\Lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c108fba5028c4b00a90d8cd936a03407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d437f48d6143529149a309d39ef5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.6996\n",
      "Epoch [1/25], Val Loss: 0.2245, Val F1: 0.6996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094a3af886de41e1aca1c8e0bf4f41fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f526e7d7a734acc815a3cedc386a5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.8477\n",
      "Epoch [2/25], Val Loss: 0.1652, Val F1: 0.8477\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7cec261da854fcf9ada132738d0dba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72587d7912e84cd193b1c327b0068e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.8604\n",
      "Epoch [3/25], Val Loss: 0.1338, Val F1: 0.8604\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa64739fb63042a5beee91d91a7ffe2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da2b02032a64063a0bb579a0ac14b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.8996\n",
      "Epoch [4/25], Val Loss: 0.0986, Val F1: 0.8996\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db0923ccb344af58cf1924a8d6fbbe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca081e380f5646e5a773ec5242528399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.9166\n",
      "Epoch [5/25], Val Loss: 0.1089, Val F1: 0.9166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4510d9eb2f4c408ab8534d6bb4373831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8720eab1c716414fbcb1aa770646726a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.9264\n",
      "Epoch [6/25], Val Loss: 0.0989, Val F1: 0.9264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4c8ca5e7ed4eddb730739f90cb141f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d717575cd20b43329ba9cbacbbcde299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/25], Val Loss: 0.0943, Val F1: 0.9254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bccd757ed6b4dad8727e2bf44a427ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91027b60a87a447c954d59db47cc6f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.9274\n",
      "Epoch [8/25], Val Loss: 0.0960, Val F1: 0.9274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb87af24975c48f780bfb72b2fa02073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac12245649d34ee7b30460718a468d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/25], Val Loss: 0.0987, Val F1: 0.9038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a194eb6100704122ab53ccfd9e87ba62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95e8629f0e0499daa1d37d89f92c154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/25], Val Loss: 0.0985, Val F1: 0.9261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308c74b39f4e464984b1862882e25194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f768708d5b1b48b39924a073f4b914b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/25], Val Loss: 0.0983, Val F1: 0.9269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3688fdaea4c845be88fa3baf0686d4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e102195f4d44d7f8c99550a403e442e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.9289\n",
      "Epoch [12/25], Val Loss: 0.0949, Val F1: 0.9289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b478e6fd782a4503940cde5ed4f00c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89d5a173adc84fe7bf07843f3afbb345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/25], Val Loss: 0.0961, Val F1: 0.9275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9169283407f241228b919ff354b7a119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898d5fe8c5904188a62abb48502cdbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.9318\n",
      "Epoch [14/25], Val Loss: 0.0956, Val F1: 0.9318\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f07d49853f49a386fe820b63e6e69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3a7c38054d44c79b30ac88763440ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/25], Val Loss: 0.0951, Val F1: 0.9012\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbac50f16804739b187d8f36b241899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2cf49400297466c86918859bbeea9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/25], Val Loss: 0.0958, Val F1: 0.9056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efe95caced74d69ad8d894dd088d5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f55788d97bb4f35ada931db3c2daf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/25], Val Loss: 0.0956, Val F1: 0.9281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642d9ac4c3fe4a22a4f2da1a96b69e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2a1ddcc8024f8c9f02e5d7a69a86b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/25], Val Loss: 0.0986, Val F1: 0.9272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b10cc87012146d2955b4153c2cb7990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42bcade9623e449e958fae49acd67763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/25], Val Loss: 0.0947, Val F1: 0.9284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da053ba2df6406495abf2b5ef061312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade4f9f1052342c188a6ff39ef980a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/25], Val Loss: 0.0974, Val F1: 0.9309\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3cc307a30b44c99978d9de470f3ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5fc5ae975a4f8cabcee8e9f6bbc18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/25], Val Loss: 0.0943, Val F1: 0.9291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2673cefa5cec4e8199343fc143baae33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db547510b3284836bda84c4ae807f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with F1: 0.9336\n",
      "Epoch [22/25], Val Loss: 0.0955, Val F1: 0.9336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae9d5b479354d00a466c6ab7a786605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f7b6d72ef064f7c8ed155a2996d6e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/25], Val Loss: 0.0962, Val F1: 0.9264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11680b62d4954a81b7da9db47d6ab61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "492cfcb49d464642a44c6b64c9afc446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/25], Val Loss: 0.0967, Val F1: 0.9283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b51857d7c19432aa379eb83b1626324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d75ebc04e27c45ca974f099208eb0406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/25], Val Loss: 0.0983, Val F1: 0.9272\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet(num_classes=data[\"unified_class\"].nunique()).to(device)\n",
    "\n",
    "\n",
    "# Инициализируем функцию потерь (loss/criterion), а так же оптимизатор, который будет регулировать обновление весов нашей модели\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Переменные для визуализации метрик и функции потерь\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# Для удобства оценивать качество модели будем той же метрику, что на лидерборде - F1 score\n",
    "train_f1_scores = []\n",
    "val_f1_scores = []\n",
    "\n",
    "best_val_f1 = 0.0\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "# Определим, сколько раз мы пройдёмся по всему датасету, прежде, чем закончим обучение модели и выберем лучшую версию\n",
    "num_epochs = 25\n",
    "\n",
    "# Шаговое уменьшение (StepLR)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.1)  # Каждые 5 эпох уменьшать lr в 10 раз\n",
    "\n",
    "# Напишем свой train_loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    train_true = []\n",
    "    train_pred = []\n",
    "\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model((inputs, labels))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "    scheduler.step()\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_true = []\n",
    "    val_pred = []\n",
    "\n",
    "    # валидационный цикл, когда мы оцениваем качество работы модели на отложенной выборке\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_dataloader):\n",
    "            inputs, labels = batch\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model((inputs, labels))\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            val_true.extend(labels.cpu().numpy())\n",
    "            val_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    val_f1 = f1_score(val_true, val_pred, average='macro')\n",
    "    val_losses.append(val_running_loss / len(valid_dataloader))\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    # если получившаяся модель лучше предыдущей, сохраним чекпоинт\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'New best model saved with F1: {best_val_f1:.4f}')\n",
    "\n",
    "\n",
    "    # выведем в консоль получившиеся результаты на отдельной эпохе\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Val Loss: {val_losses[-1]:.4f}, Val F1: {val_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(r\"journey-springfield\\sample_submission.csv\")\n",
    "sample['image_name'] = r'journey-springfield/testset/'+sample['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_13604\\520478481.py:33: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_model_path))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baf315b909d45cdbfdd760e0ee2180b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Expected",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "image_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "predicted_class",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "bdba0fc2-c182-4e1f-a952-06c2816f55b4",
       "rows": [
        [
         "0",
         "img0.jpg",
         "bart_simpson",
         "journey-springfield/testset/img0.jpg",
         "29"
        ],
        [
         "1",
         "img1.jpg",
         "bart_simpson",
         "journey-springfield/testset/img1.jpg",
         "4"
        ],
        [
         "2",
         "img2.jpg",
         "bart_simpson",
         "journey-springfield/testset/img2.jpg",
         "24"
        ],
        [
         "3",
         "img3.jpg",
         "bart_simpson",
         "journey-springfield/testset/img3.jpg",
         "29"
        ],
        [
         "4",
         "img4.jpg",
         "bart_simpson",
         "journey-springfield/testset/img4.jpg",
         "20"
        ],
        [
         "5",
         "img5.jpg",
         "bart_simpson",
         "journey-springfield/testset/img5.jpg",
         "32"
        ],
        [
         "6",
         "img6.jpg",
         "bart_simpson",
         "journey-springfield/testset/img6.jpg",
         "17"
        ],
        [
         "7",
         "img7.jpg",
         "bart_simpson",
         "journey-springfield/testset/img7.jpg",
         "2"
        ],
        [
         "8",
         "img8.jpg",
         "bart_simpson",
         "journey-springfield/testset/img8.jpg",
         "32"
        ],
        [
         "9",
         "img9.jpg",
         "bart_simpson",
         "journey-springfield/testset/img9.jpg",
         "9"
        ],
        [
         "10",
         "img10.jpg",
         "bart_simpson",
         "journey-springfield/testset/img10.jpg",
         "28"
        ],
        [
         "11",
         "img11.jpg",
         "bart_simpson",
         "journey-springfield/testset/img11.jpg",
         "28"
        ],
        [
         "12",
         "img12.jpg",
         "bart_simpson",
         "journey-springfield/testset/img12.jpg",
         "15"
        ],
        [
         "13",
         "img13.jpg",
         "bart_simpson",
         "journey-springfield/testset/img13.jpg",
         "0"
        ],
        [
         "14",
         "img14.jpg",
         "bart_simpson",
         "journey-springfield/testset/img14.jpg",
         "29"
        ],
        [
         "15",
         "img15.jpg",
         "bart_simpson",
         "journey-springfield/testset/img15.jpg",
         "6"
        ],
        [
         "16",
         "img16.jpg",
         "bart_simpson",
         "journey-springfield/testset/img16.jpg",
         "24"
        ],
        [
         "17",
         "img17.jpg",
         "bart_simpson",
         "journey-springfield/testset/img17.jpg",
         "9"
        ],
        [
         "18",
         "img18.jpg",
         "bart_simpson",
         "journey-springfield/testset/img18.jpg",
         "15"
        ],
        [
         "19",
         "img19.jpg",
         "bart_simpson",
         "journey-springfield/testset/img19.jpg",
         "25"
        ],
        [
         "20",
         "img20.jpg",
         "bart_simpson",
         "journey-springfield/testset/img20.jpg",
         "22"
        ],
        [
         "21",
         "img21.jpg",
         "bart_simpson",
         "journey-springfield/testset/img21.jpg",
         "32"
        ],
        [
         "22",
         "img22.jpg",
         "bart_simpson",
         "journey-springfield/testset/img22.jpg",
         "27"
        ],
        [
         "23",
         "img23.jpg",
         "bart_simpson",
         "journey-springfield/testset/img23.jpg",
         "7"
        ],
        [
         "24",
         "img24.jpg",
         "bart_simpson",
         "journey-springfield/testset/img24.jpg",
         "7"
        ],
        [
         "25",
         "img25.jpg",
         "bart_simpson",
         "journey-springfield/testset/img25.jpg",
         "2"
        ],
        [
         "26",
         "img26.jpg",
         "bart_simpson",
         "journey-springfield/testset/img26.jpg",
         "0"
        ],
        [
         "27",
         "img27.jpg",
         "bart_simpson",
         "journey-springfield/testset/img27.jpg",
         "11"
        ],
        [
         "28",
         "img28.jpg",
         "bart_simpson",
         "journey-springfield/testset/img28.jpg",
         "15"
        ],
        [
         "29",
         "img29.jpg",
         "bart_simpson",
         "journey-springfield/testset/img29.jpg",
         "27"
        ],
        [
         "30",
         "img30.jpg",
         "bart_simpson",
         "journey-springfield/testset/img30.jpg",
         "17"
        ],
        [
         "31",
         "img31.jpg",
         "bart_simpson",
         "journey-springfield/testset/img31.jpg",
         "9"
        ],
        [
         "32",
         "img32.jpg",
         "bart_simpson",
         "journey-springfield/testset/img32.jpg",
         "6"
        ],
        [
         "33",
         "img33.jpg",
         "bart_simpson",
         "journey-springfield/testset/img33.jpg",
         "22"
        ],
        [
         "34",
         "img34.jpg",
         "bart_simpson",
         "journey-springfield/testset/img34.jpg",
         "11"
        ],
        [
         "35",
         "img35.jpg",
         "bart_simpson",
         "journey-springfield/testset/img35.jpg",
         "37"
        ],
        [
         "36",
         "img36.jpg",
         "bart_simpson",
         "journey-springfield/testset/img36.jpg",
         "7"
        ],
        [
         "37",
         "img37.jpg",
         "bart_simpson",
         "journey-springfield/testset/img37.jpg",
         "27"
        ],
        [
         "38",
         "img38.jpg",
         "bart_simpson",
         "journey-springfield/testset/img38.jpg",
         "27"
        ],
        [
         "39",
         "img39.jpg",
         "bart_simpson",
         "journey-springfield/testset/img39.jpg",
         "27"
        ],
        [
         "40",
         "img40.jpg",
         "bart_simpson",
         "journey-springfield/testset/img40.jpg",
         "27"
        ],
        [
         "41",
         "img41.jpg",
         "bart_simpson",
         "journey-springfield/testset/img41.jpg",
         "29"
        ],
        [
         "42",
         "img42.jpg",
         "bart_simpson",
         "journey-springfield/testset/img42.jpg",
         "9"
        ],
        [
         "43",
         "img43.jpg",
         "bart_simpson",
         "journey-springfield/testset/img43.jpg",
         "24"
        ],
        [
         "44",
         "img44.jpg",
         "bart_simpson",
         "journey-springfield/testset/img44.jpg",
         "11"
        ],
        [
         "45",
         "img45.jpg",
         "bart_simpson",
         "journey-springfield/testset/img45.jpg",
         "11"
        ],
        [
         "46",
         "img46.jpg",
         "bart_simpson",
         "journey-springfield/testset/img46.jpg",
         "17"
        ],
        [
         "47",
         "img47.jpg",
         "bart_simpson",
         "journey-springfield/testset/img47.jpg",
         "32"
        ],
        [
         "48",
         "img48.jpg",
         "bart_simpson",
         "journey-springfield/testset/img48.jpg",
         "24"
        ],
        [
         "49",
         "img49.jpg",
         "bart_simpson",
         "journey-springfield/testset/img49.jpg",
         "25"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 991
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Expected</th>\n",
       "      <th>image_name</th>\n",
       "      <th>predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img0.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img0.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img1.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img1.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img2.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img2.jpg</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img3.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img3.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img4.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img4.jpg</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>img986.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img986.jpg</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>img987.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img987.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>img988.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img988.jpg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>img989.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img989.jpg</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>img990.jpg</td>\n",
       "      <td>bart_simpson</td>\n",
       "      <td>journey-springfield/testset/img990.jpg</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>991 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id      Expected                              image_name  \\\n",
       "0      img0.jpg  bart_simpson    journey-springfield/testset/img0.jpg   \n",
       "1      img1.jpg  bart_simpson    journey-springfield/testset/img1.jpg   \n",
       "2      img2.jpg  bart_simpson    journey-springfield/testset/img2.jpg   \n",
       "3      img3.jpg  bart_simpson    journey-springfield/testset/img3.jpg   \n",
       "4      img4.jpg  bart_simpson    journey-springfield/testset/img4.jpg   \n",
       "..          ...           ...                                     ...   \n",
       "986  img986.jpg  bart_simpson  journey-springfield/testset/img986.jpg   \n",
       "987  img987.jpg  bart_simpson  journey-springfield/testset/img987.jpg   \n",
       "988  img988.jpg  bart_simpson  journey-springfield/testset/img988.jpg   \n",
       "989  img989.jpg  bart_simpson  journey-springfield/testset/img989.jpg   \n",
       "990  img990.jpg  bart_simpson  journey-springfield/testset/img990.jpg   \n",
       "\n",
       "     predicted_class  \n",
       "0                 29  \n",
       "1                  4  \n",
       "2                 24  \n",
       "3                 29  \n",
       "4                 20  \n",
       "..               ...  \n",
       "986               37  \n",
       "987               29  \n",
       "988               28  \n",
       "989                6  \n",
       "990               17  \n",
       "\n",
       "[991 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class InferenceDataset(Dataset):\n",
    "    def __init__(self, image_paths, transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        return image, image_path\n",
    "\n",
    "\n",
    "# Тут важно не ошибиться и не использовать тренировочные трансформы\n",
    "infer_transform = tt.Compose([\n",
    "    tt.RandomHorizontalFlip(),\n",
    "    tt.RandomRotation((-5, 5)),\n",
    "    tt.Resize((int(244 * 1.25), int(244 * 1.25))),\n",
    "    tt.ToTensor(),\n",
    "    tt.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Найдем все тестовые картинки\n",
    "test_image_paths = sample.image_name.tolist()\n",
    "\n",
    "infer_dataset = InferenceDataset(test_image_paths, transforms=infer_transform)\n",
    "infer_dataloader = DataLoader(infer_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "best_model_path = r'best_model.pth'\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "\n",
    "# Не забудем перевести модель в режим предсказания, а не обучения.\n",
    "model.eval()\n",
    "\n",
    "# Для ускорения инференса будем подавать в модель картинки батчами (по несколько картинок за раз) и сохраним предсказанные метки классов.\n",
    "results = []\n",
    "for images, image_names in tqdm(infer_dataloader):\n",
    "    images = images.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model((images, None)) #для не хагина\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        results.append(preds[0])\n",
    "\n",
    "\n",
    "# Для удобства объединим все пары \"имя файла - предсказанный класс\" в датафрейм (таблицу) с колонками image_name, predicted_class\n",
    "sample['predicted_class'] = results\n",
    "\n",
    "# Вывод DataFrame\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample['Expected'] = le1.inverse_transform(sample['predicted_class'])\n",
    "sample.drop(['image_name','predicted_class'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('submit.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
